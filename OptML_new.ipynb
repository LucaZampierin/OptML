{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IZ2s6PmzSm_n"
      },
      "source": [
        "Key steps for assignment:\n",
        "- Get the data for the comparison\n",
        "- Get the models used for hte comparison\n",
        "- Train the models with suggested hyperparameters (compare the test results with a given number of epochs)\n",
        "- OR train the models until convergence and compare the resutls (number of steps and test results)\n",
        "- Hyperparameter tuninig for a fixed number of trials\n",
        "- Compare the improvements with tuning\n",
        "\n",
        "Tasks:\n",
        "- image classification (CIFAR10, CIFAR100) -> ResNet18, ResNet34, ResNet50 (but freaking huge)\n",
        "- image recognition (ImageNet (maybe)) -> ResNet18 or ResNet50 (ImageNet more pain in the ass to download)\n",
        "- Denosing (SIDD dataset) -> UNet or ResUnet\n",
        "- GAN (CIFAR10) -> WassersteinGAN\n",
        "- Language modelling (Penn TreeBank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting madgrad\n",
            "  Downloading madgrad-1.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: madgrad\n",
            "Successfully installed madgrad-1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adabelief-pytorch==0.2.0\n",
            "  Downloading adabelief_pytorch-0.2.0-py3-none-any.whl (5.7 kB)\n",
            "Collecting colorama>=0.4.0\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch==0.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch==0.2.0) (0.8.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabelief-pytorch==0.2.0) (4.2.0)\n",
            "Installing collected packages: colorama, adabelief-pytorch\n",
            "Successfully installed adabelief-pytorch-0.2.0 colorama-0.4.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 12.8 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=1e43c36b5cde92c2add9bdd3afcfb5ae9d5014e3789758c89a129ffe853e6374\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install madgrad\n",
        "! pip install adabelief-pytorch==0.2.0\n",
        "! pip install optuna"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKZqL0joSm_p",
        "outputId": "7854b429-32bc-4eea-95dc-d1943b71b137"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import relevant libraries"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rxdfD75cSm_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/EPFL/OptML/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVAD3KNsTFTS",
        "outputId": "c04fc89d-95b6-4519-83bd-fb4d83edb73e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from adabelief_pytorch import AdaBelief\n",
        "from madgrad import MADGRAD\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0fTS3UhZSm_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ezXVTvQ3Sm_s",
        "outputId": "faf09719-6c8e-44b6-9d53-cb7d7551c1fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kGhr9QEsSm_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bee770fd7094e5fb57be0d5d2adbb62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# data = \"CIFAR10\"\n",
        "data = \"CIFAR100\"\n",
        "# data = \"ImageNet\"\n",
        "\n",
        "if data == \"CIFAR10\":\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset= torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                              shuffle=True)\n",
        "    testset= torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                             shuffle=False)\n",
        "if data == \"CIFAR100\":\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                              shuffle=True)\n",
        "    testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                             shuffle=False)\n",
        "\n",
        "# For now not working. Need to download the data locally first\n",
        "if data == \"ImageNet\":\n",
        "    trainset = torchvision.datasets.ImageNet(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                              shuffle=True)\n",
        "    testset = torchvision.datasets.ImageNet(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                             shuffle=False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "7bee770fd7094e5fb57be0d5d2adbb62",
            "eec614ddca984038b1394eaa838a0f22",
            "4bf7bc9c2f15466d8f4a8371d61f5e89",
            "31b0c52ffd7a48a19361a967c1ea3c22",
            "6564ed17168e4f16b21551fb70550c2e",
            "fdf6245425454812a91fbee19cde0444",
            "a40b59c45a99408e9d96224f71015c98",
            "31607cd4fb734224af974b308d203b9f",
            "c8020d6c47a349c88a94b55215d95feb",
            "3b2cbe6b9dba4edeb2488d112d9608b3",
            "0064a9f679094576acd0437eabb9a103"
          ]
        },
        "id": "DchoKxw-Sm_t",
        "outputId": "15b20b92-b58a-40dc-eccf-5c0ea8a96571"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Choose the model to use (uncomment the line)\n",
        "\n",
        "model = models.resnet18()\n",
        "# model = models.resnet34()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gxcGbjHdSm_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Loss and optimizers with suggested hyperparameters for CIFAR\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = AdaBelief(model.parameters(), lr=0.001, betas=(0.9,0.999), eps=1e-16, weight_decouple=False, rectify=False) #fixed_decay=False, amsgrad=False, weight_decay=5e-4\n",
        "optimizer = MADGRAD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0, eps=1e-6, decouple_decay=False)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ieQTUbo2Sm_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mlZomO2lSm_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Epoch [1/100], Step [100/391] Loss: 3.9122\n",
            "Epoch [1/100], Step [200/391] Loss: 3.6655\n",
            "Epoch [1/100], Step [300/391] Loss: 3.2181\n",
            "Epoch [2/100], Step [100/391] Loss: 2.8345\n",
            "Epoch [2/100], Step [200/391] Loss: 2.8137\n",
            "Epoch [2/100], Step [300/391] Loss: 2.7727\n",
            "Epoch [3/100], Step [100/391] Loss: 2.3629\n",
            "Epoch [3/100], Step [200/391] Loss: 2.6977\n",
            "Epoch [3/100], Step [300/391] Loss: 2.4743\n",
            "Epoch [4/100], Step [100/391] Loss: 2.4323\n",
            "Epoch [4/100], Step [200/391] Loss: 2.0863\n",
            "Epoch [4/100], Step [300/391] Loss: 2.0844\n",
            "Epoch [5/100], Step [100/391] Loss: 2.1603\n",
            "Epoch [5/100], Step [200/391] Loss: 2.0319\n",
            "Epoch [5/100], Step [300/391] Loss: 1.8183\n",
            "Epoch [6/100], Step [100/391] Loss: 1.8479\n",
            "Epoch [6/100], Step [200/391] Loss: 1.6344\n",
            "Epoch [6/100], Step [300/391] Loss: 1.6973\n",
            "Epoch [7/100], Step [100/391] Loss: 1.2776\n",
            "Epoch [7/100], Step [200/391] Loss: 1.6793\n",
            "Epoch [7/100], Step [300/391] Loss: 1.6114\n",
            "Epoch [8/100], Step [100/391] Loss: 1.2827\n",
            "Epoch [8/100], Step [200/391] Loss: 1.1564\n",
            "Epoch [8/100], Step [300/391] Loss: 1.2043\n",
            "Epoch [9/100], Step [100/391] Loss: 1.0031\n",
            "Epoch [9/100], Step [200/391] Loss: 1.3824\n",
            "Epoch [9/100], Step [300/391] Loss: 1.2763\n",
            "Epoch [10/100], Step [100/391] Loss: 0.7744\n",
            "Epoch [10/100], Step [200/391] Loss: 0.8227\n",
            "Epoch [10/100], Step [300/391] Loss: 1.1959\n",
            "Epoch [11/100], Step [100/391] Loss: 0.5349\n",
            "Epoch [11/100], Step [200/391] Loss: 0.6859\n",
            "Epoch [11/100], Step [300/391] Loss: 0.6113\n",
            "Epoch [12/100], Step [100/391] Loss: 0.4203\n",
            "Epoch [12/100], Step [200/391] Loss: 0.3856\n",
            "Epoch [12/100], Step [300/391] Loss: 0.5389\n",
            "Epoch [13/100], Step [100/391] Loss: 0.3375\n",
            "Epoch [13/100], Step [200/391] Loss: 0.4608\n",
            "Epoch [13/100], Step [300/391] Loss: 0.4768\n",
            "Epoch [14/100], Step [100/391] Loss: 0.3331\n",
            "Epoch [14/100], Step [200/391] Loss: 0.3940\n",
            "Epoch [14/100], Step [300/391] Loss: 0.3155\n",
            "Epoch [15/100], Step [100/391] Loss: 0.3261\n",
            "Epoch [15/100], Step [200/391] Loss: 0.2685\n",
            "Epoch [15/100], Step [300/391] Loss: 0.3200\n",
            "Epoch [16/100], Step [100/391] Loss: 0.1373\n",
            "Epoch [16/100], Step [200/391] Loss: 0.2717\n",
            "Epoch [16/100], Step [300/391] Loss: 0.2438\n",
            "Epoch [17/100], Step [100/391] Loss: 0.1365\n",
            "Epoch [17/100], Step [200/391] Loss: 0.1489\n",
            "Epoch [17/100], Step [300/391] Loss: 0.1522\n",
            "Epoch [18/100], Step [100/391] Loss: 0.2625\n",
            "Epoch [18/100], Step [200/391] Loss: 0.2023\n",
            "Epoch [18/100], Step [300/391] Loss: 0.3385\n",
            "Epoch [19/100], Step [100/391] Loss: 0.0978\n",
            "Epoch [19/100], Step [200/391] Loss: 0.1769\n",
            "Epoch [19/100], Step [300/391] Loss: 0.2636\n",
            "Epoch [20/100], Step [100/391] Loss: 0.2473\n",
            "Epoch [20/100], Step [200/391] Loss: 0.1430\n",
            "Epoch [20/100], Step [300/391] Loss: 0.1802\n",
            "Epoch [21/100], Step [100/391] Loss: 0.1049\n",
            "Epoch [21/100], Step [200/391] Loss: 0.1398\n",
            "Epoch [21/100], Step [300/391] Loss: 0.1307\n",
            "Epoch [22/100], Step [100/391] Loss: 0.1730\n",
            "Epoch [22/100], Step [200/391] Loss: 0.2072\n",
            "Epoch [22/100], Step [300/391] Loss: 0.1370\n",
            "Epoch [23/100], Step [100/391] Loss: 0.0996\n",
            "Epoch [23/100], Step [200/391] Loss: 0.0999\n",
            "Epoch [23/100], Step [300/391] Loss: 0.2087\n",
            "Epoch [24/100], Step [100/391] Loss: 0.0619\n",
            "Epoch [24/100], Step [200/391] Loss: 0.1171\n",
            "Epoch [24/100], Step [300/391] Loss: 0.0897\n",
            "Epoch [25/100], Step [100/391] Loss: 0.0924\n",
            "Epoch [25/100], Step [200/391] Loss: 0.1643\n",
            "Epoch [25/100], Step [300/391] Loss: 0.1556\n",
            "Epoch [26/100], Step [100/391] Loss: 0.0918\n",
            "Epoch [26/100], Step [200/391] Loss: 0.1779\n",
            "Epoch [26/100], Step [300/391] Loss: 0.1254\n",
            "Epoch [27/100], Step [100/391] Loss: 0.0927\n",
            "Epoch [27/100], Step [200/391] Loss: 0.1581\n",
            "Epoch [27/100], Step [300/391] Loss: 0.1575\n",
            "Epoch [28/100], Step [100/391] Loss: 0.0344\n",
            "Epoch [28/100], Step [200/391] Loss: 0.0948\n",
            "Epoch [28/100], Step [300/391] Loss: 0.0849\n",
            "Epoch [29/100], Step [100/391] Loss: 0.0788\n",
            "Epoch [29/100], Step [200/391] Loss: 0.1234\n",
            "Epoch [29/100], Step [300/391] Loss: 0.1191\n",
            "Epoch [30/100], Step [100/391] Loss: 0.1085\n",
            "Epoch [30/100], Step [200/391] Loss: 0.1313\n",
            "Epoch [30/100], Step [300/391] Loss: 0.2341\n",
            "Epoch [31/100], Step [100/391] Loss: 0.1411\n",
            "Epoch [31/100], Step [200/391] Loss: 0.1204\n",
            "Epoch [31/100], Step [300/391] Loss: 0.1596\n",
            "Epoch [32/100], Step [100/391] Loss: 0.0768\n",
            "Epoch [32/100], Step [200/391] Loss: 0.1150\n",
            "Epoch [32/100], Step [300/391] Loss: 0.2037\n",
            "Epoch [33/100], Step [100/391] Loss: 0.0661\n",
            "Epoch [33/100], Step [200/391] Loss: 0.1259\n",
            "Epoch [33/100], Step [300/391] Loss: 0.1050\n",
            "Epoch [34/100], Step [100/391] Loss: 0.0575\n",
            "Epoch [34/100], Step [200/391] Loss: 0.1491\n",
            "Epoch [34/100], Step [300/391] Loss: 0.1005\n",
            "Epoch [35/100], Step [100/391] Loss: 0.0792\n",
            "Epoch [35/100], Step [200/391] Loss: 0.1226\n",
            "Epoch [35/100], Step [300/391] Loss: 0.1109\n",
            "Epoch [36/100], Step [100/391] Loss: 0.0816\n",
            "Epoch [36/100], Step [200/391] Loss: 0.0310\n",
            "Epoch [36/100], Step [300/391] Loss: 0.0654\n",
            "Epoch [37/100], Step [100/391] Loss: 0.1142\n",
            "Epoch [37/100], Step [200/391] Loss: 0.1314\n",
            "Epoch [37/100], Step [300/391] Loss: 0.1354\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(i) \n",
        "    start_time = time.time()\n",
        "    torch.manual_seed(i)    \n",
        "    # model = models.resnet18()\n",
        "    model = models.resnet34()\n",
        "    # Loss and optimizers with suggested hyperparameters for CIFAR\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdaBelief(model.parameters(), lr=0.001, betas=(0.9,0.999), eps=1e-16, weight_decouple=False, rectify=False) #fixed_decay=False, amsgrad=False, weight_decay=5e-4\n",
        "    # optimizer = MADGRAD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0, eps=1e-6, decouple_decay=False)\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # Train the model for image classification\n",
        "    model.to(device)\n",
        "    num_epochs = 100\n",
        "    total_step = len(trainloader)\n",
        "    loss_trial = []\n",
        "    acc_trial = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for j, (images, labels) in enumerate(trainloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (j+1) % 100 == 0:\n",
        "                print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                      .format(epoch+1, num_epochs, j+1, total_step, loss.item()))\n",
        "        loss_trial.append(total_loss/total_step)\n",
        "        # Test the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in testloader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        acc_trial.append(100 * correct / total)\n",
        "    train_time = time.time() - start_time\n",
        "    print(train_time)\n",
        "    np.save('/content/drive/MyDrive/EPFL/OptML/loss_resnet32_adabelief_episode_{}.npy'.format(i), loss_trial)\n",
        "    np.save('/content/drive/MyDrive/EPFL/OptML/acc_resnet32_adabelief_episode_{}.npy'.format(i), acc_trial)\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KJ9M0rpgSm_y",
        "outputId": "9ccb36bb-8c23-49f1-f7d1-2c75ac16387b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/EPFL/OptML/losses_resnet18_sgd.npy', losses)\n",
        "np.save('/content/drive/MyDrive/EPFL/OptML/accs_resnet18_sgd.npy', accuracies)"
      ],
      "metadata": {
        "id": "Eryd6KNjT9zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 77.62 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r8eMp4G2Sm_z",
        "outputId": "d1241767-44f5-4116-fc3c-a3cdba8f1311"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iFgarwlfSm_z"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "OptML_new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bee770fd7094e5fb57be0d5d2adbb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eec614ddca984038b1394eaa838a0f22",
              "IPY_MODEL_4bf7bc9c2f15466d8f4a8371d61f5e89",
              "IPY_MODEL_31b0c52ffd7a48a19361a967c1ea3c22"
            ],
            "layout": "IPY_MODEL_6564ed17168e4f16b21551fb70550c2e"
          }
        },
        "eec614ddca984038b1394eaa838a0f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf6245425454812a91fbee19cde0444",
            "placeholder": "​",
            "style": "IPY_MODEL_a40b59c45a99408e9d96224f71015c98",
            "value": ""
          }
        },
        "4bf7bc9c2f15466d8f4a8371d61f5e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31607cd4fb734224af974b308d203b9f",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8020d6c47a349c88a94b55215d95feb",
            "value": 169001437
          }
        },
        "31b0c52ffd7a48a19361a967c1ea3c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b2cbe6b9dba4edeb2488d112d9608b3",
            "placeholder": "​",
            "style": "IPY_MODEL_0064a9f679094576acd0437eabb9a103",
            "value": " 169001984/? [00:06&lt;00:00, 26893020.92it/s]"
          }
        },
        "6564ed17168e4f16b21551fb70550c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf6245425454812a91fbee19cde0444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40b59c45a99408e9d96224f71015c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31607cd4fb734224af974b308d203b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8020d6c47a349c88a94b55215d95feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b2cbe6b9dba4edeb2488d112d9608b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0064a9f679094576acd0437eabb9a103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}