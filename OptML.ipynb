{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Key steps for assignment:\n",
    "- Get the data for the comparison\n",
    "- Get the models used for hte comparison\n",
    "- Train the models with suggested hyperparameters (compare the test results with a given number of epochs)\n",
    "- OR train the models until convergence and compare the resutls (number of steps and test results)\n",
    "- Hyperparameter tuninig for a fixed number of trials\n",
    "- Compare the improvements with tuning\n",
    "\n",
    "Tasks:\n",
    "- image classification (CIFAR10, CIFAR100) -> ResNet18, ResNet34, ResNet50 (but freaking huge)\n",
    "- image recognition (ImageNet (maybe)) -> ResNet18 or ResNet50 (ImageNet more pain in the ass to download)\n",
    "- Denosing (SIDD dataset) -> UNet or ResUnet\n",
    "- GAN (CIFAR10) -> WassersteinGAN\n",
    "- Language modelling (Penn TreeBank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: madgrad in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lucaz\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adabelief-pytorch==0.2.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: tabulate>=0.7 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from adabelief-pytorch==0.2.0) (0.8.9)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from adabelief-pytorch==0.2.0) (0.4.3)\n",
      "Requirement already satisfied: torch>=0.4.0 in c:\\users\\lucaz\\appdata\\roaming\\python\\python37\\site-packages (from adabelief-pytorch==0.2.0) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from torch>=0.4.0->adabelief-pytorch==0.2.0) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lucaz\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (1.18.1)\n",
      "Requirement already satisfied: alembic in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (1.7.7)\n",
      "Requirement already satisfied: cliff in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (4.42.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (5.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (20.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from optuna) (1.3.13)\n",
      "Requirement already satisfied: six in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from alembic->optuna) (4.11.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from alembic->optuna) (5.7.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.2.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.5.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.8.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.1.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (19.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic->optuna) (3.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\lucaz\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lucaz\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install madgrad\n",
    "! pip install adabelief-pytorch==0.2.0\n",
    "! pip install optuna"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import relevant libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from madgrad import MADGRAD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DATA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = \"CIFAR10\"\n",
    "# data = \"CIFAR100\"\n",
    "# data = \"ImageNet\"\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset= torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                              shuffle=True)\n",
    "    testset= torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                             shuffle=False)\n",
    "if data == \"CIFAR100\":\n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                              shuffle=True)\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                             shuffle=False)\n",
    "\n",
    "# For now not working. Need to download the data locally first\n",
    "if data == \"ImageNet\":\n",
    "    trainset = torchvision.datasets.ImageNet(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                              shuffle=True)\n",
    "    testset = torchvision.datasets.ImageNet(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                             shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Choose the model to use (uncomment the line)\n",
    "\n",
    "model = models.resnet18()\n",
    "# model = models.resnet34()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Loss and optimizers with suggested hyperparameters for CIFAR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = AdaBelief(model.parameters(), lr=0.001, betas=(0.9,0.999), eps=1e-16, weight_decouple=False, rectify=False) #fixed_decay=False, amsgrad=False, weight_decay=5e-4\n",
    "optimizer = MADGRAD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0, eps=1e-6, decouple_decay=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/391] Loss: 1.6398\n",
      "Epoch [1/5], Step [200/391] Loss: 1.6111\n",
      "Epoch [1/5], Step [300/391] Loss: 1.3022\n",
      "Epoch [2/5], Step [100/391] Loss: 1.3663\n",
      "Epoch [2/5], Step [200/391] Loss: 1.1516\n",
      "Epoch [2/5], Step [300/391] Loss: 1.1648\n",
      "Epoch [3/5], Step [100/391] Loss: 0.8393\n",
      "Epoch [3/5], Step [200/391] Loss: 1.1248\n",
      "Epoch [3/5], Step [300/391] Loss: 0.8392\n",
      "Epoch [4/5], Step [100/391] Loss: 1.0720\n",
      "Epoch [4/5], Step [200/391] Loss: 0.7634\n",
      "Epoch [4/5], Step [300/391] Loss: 0.6591\n",
      "Epoch [5/5], Step [100/391] Loss: 0.7404\n",
      "Epoch [5/5], Step [200/391] Loss: 0.5967\n",
      "Epoch [5/5], Step [300/391] Loss: 0.6569\n"
     ]
    }
   ],
   "source": [
    "# Train the model for image classification\n",
    "model.to(device)\n",
    "num_epochs = 200\n",
    "total_step = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 70.88 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}